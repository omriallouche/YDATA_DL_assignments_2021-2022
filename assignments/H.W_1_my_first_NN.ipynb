{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Copy of transfer_learning_tutorial.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gI-StW3hbGOA"
      },
      "source": [
        "# Tutorial for training a NN for the first time\n",
        "\n",
        "**Extended from [code](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html) by [Sasank Chilamkurthy](https://chsasank.github.io).**  \n",
        "License: BSD.\n",
        "\n",
        "In this tutorial, you will learn how to train a neural network for\n",
        "image classification using a pre-trained model (transfer learning). You can read more about the transfer\n",
        "learning at the [CS231N notes](https://cs231n.github.io/transfer-learning/).\n",
        "\n",
        "The goal of this assignments is to practice how to train given a nueral network and how to analyze its results. We supplied the code for loading the data, defining the network architecture and training it. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50cENrbGpDBv"
      },
      "source": [
        "### Running notes\n",
        "If you are running this in Google Colab, be sure to change the runtime to GPU by clicking `Runtime > Change runtime type` and selecting \"GPU\" from the dropdown menu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rel9uaEopKl8"
      },
      "source": [
        "### Import relevant packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-10T15:55:52.574224Z",
          "start_time": "2021-02-10T15:55:52.557599Z"
        },
        "id": "1URABfT2bGN6"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rP-HFfuxRfTU"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-10T15:55:56.447307Z",
          "start_time": "2021-02-10T15:55:56.442307Z"
        },
        "id": "dH4A1mP4bGOB"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "plt.ion()   # interactive mode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "td68sj5ZbGOB"
      },
      "source": [
        "## Load Data\n",
        "\n",
        "We will use `torchvision` and `torch.utils.data` packages for loading the\n",
        "data.\n",
        "\n",
        "The problem we're going to solve today is to train a model to classify\n",
        "present and future **Israeli politicians**. We have about ~100 training images for each of our 9 politicians, scraped from the first page of the Google Images Search.\n",
        "Usually, this is a very small dataset to generalize upon, if trained from scratch (or is it? We'll soon test this ourselves during the course!). Since we are using transfer learning, we should be able to generalize reasonably well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-01-05T08:25:43.697021Z",
          "start_time": "2021-01-05T08:25:43.634378Z"
        },
        "id": "Imt6bHRcpKl8"
      },
      "source": [
        "# Create a folder for our data\n",
        "!mkdir data\n",
        "!mkdir data/israeli_politicians"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qiV_UKiIg7sT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-01-05T08:25:53.487927Z",
          "start_time": "2021-01-05T08:25:47.261674Z"
        },
        "id": "L3PygmilpKl9"
      },
      "source": [
        "# Download our dataset and extract it\n",
        "import requests\n",
        "from zipfile import ZipFile\n",
        "\n",
        "url = 'https://github.com/omriallouche/ydata_deep_learning_2021/blob/main/data/israeli_politicians.zip?raw=true'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "open('./data/israeli_politicians.zip', 'wb').write(r.content)\n",
        "\n",
        "with ZipFile('./data/israeli_politicians.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall(path='./data/israeli_politicians/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-01-05T08:22:39.699585Z",
          "start_time": "2021-01-05T08:22:39.646414Z"
        },
        "id": "7CltLkCkclPU"
      },
      "source": [
        "# On Linux machines, the following simpler code can be used instead\n",
        "# !wget https://github.com/omriallouche/ydata_deep_learning_2021/blob/main/data/israeli_politicians.zip?raw=true\n",
        "# !unzip israeli_politicians.zip -d data/israeli_politicians/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2DovylepKl9"
      },
      "source": [
        "### Datasets definition\n",
        "PyTorch uses DataLoaders to define datasets. We'll create 2 data loaders, `train` and `val` (for validation).  \n",
        "Our dataset was already split into different folders for these - as you can see under the \"Files\" menu on the left of the Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-10T15:56:10.524522Z",
          "start_time": "2021-02-10T15:56:10.513925Z"
        },
        "id": "1hOx1afMpKl-"
      },
      "source": [
        "means = [0.485, 0.456, 0.406]\n",
        "stds = [0.229, 0.224, 0.225]\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(means, stds)\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(means, stds)\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-10T15:56:11.038717Z",
          "start_time": "2021-02-10T15:56:11.004567Z"
        },
        "id": "_tgnnDCvbGOB"
      },
      "source": [
        "data_dir = r'./data/israeli_politicians/'\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {\n",
        "    'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=16,\n",
        "                                             shuffle=True, num_workers=4),\n",
        "    'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=16,\n",
        "                                          shuffle=False, num_workers=4)\n",
        "  }\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "print('dataset_sizes: ', dataset_sizes)\n",
        "\n",
        "class_names = image_datasets['train'].classes\n",
        "print('class_names:', class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkDZ8e0gPzk5"
      },
      "source": [
        "# Check for the availability of a GPU, and use CPU otherwise\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3CJLLEsRjIX"
      },
      "source": [
        "### Datasets and Dataloaders\n",
        "Let's examine the dataloaders and datasets and learn more about their attributes and functions.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K9ca0KWQ2SE"
      },
      "source": [
        "train_dataloader = dataloaders['train']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aISIkMZeRx8R"
      },
      "source": [
        "In Colab or Jupyter notebook, if we type  `train_dataloader.` and wait, we'd see a drop-down with the object attributes and functions.  \n",
        "\n",
        "`train_dataloader.dataset.samples` contains the filenames + true labels (0 to 8 for our 9 classes).  \n",
        "`train_dataloader.dataset.classes` contains the class names in order.  \n",
        "`train_dataloader.dataset.class_to_idx` contains a map from a class name to the integer that represents it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3SvG2F1Q8Q9"
      },
      "source": [
        "train_dataloader.dataset.class_to_idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkuFvKK8bGOC"
      },
      "source": [
        "### Visualize a few images\n",
        "\n",
        "Let's visualize a few training images so as to understand the data\n",
        "augmentations.\n",
        "Pay attention that the data loader changes the mean and the std of the images, so we need to change it back before showing them.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iSubwzdP_7k"
      },
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array(means)\n",
        "    std = np.array(stds)\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    fig = plt.figure(figsize=(5,3), dpi=300)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "       plt.title(title, fontsize=5)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZhNUM9zQBPh"
      },
      "source": [
        "# Get a batch of training data - the data loader is a generator\n",
        "inputs, classes = next(iter(dataloaders['train']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqu0VJVzQQEi"
      },
      "source": [
        "`inputs` is a tensor of shape `[16, 3, 256, 256]` - there are 16 images in the batch, each with 3 color channels (RGB), a width of 256 pixels, and a height of 256 pixels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VBut9aYQI93"
      },
      "source": [
        "inputs.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRmvBUYiQFqb"
      },
      "source": [
        "inputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlsfzvWsQndN"
      },
      "source": [
        "`classes` is a tensor of size 16, containing numbers matching the true class of each image, from our 9 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKdx9DatQFxK"
      },
      "source": [
        "classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzN2OjVBS-ix"
      },
      "source": [
        "To map it to the class names, we can run:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9mTKTGyTCRv"
      },
      "source": [
        "[class_names[c] for c in classes]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-10T15:56:18.524503Z",
          "start_time": "2021-02-10T15:56:15.328637Z"
        },
        "id": "2JFOfTKlbGOC"
      },
      "source": [
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs, nrow=8)\n",
        "imshow(out, title='\\n'.join([class_names[x] for x in classes]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9Pjza-pTwIN"
      },
      "source": [
        "### Using a pretrained model\n",
        "Let's load a model (VGG16) pretrained on ImageNet, and use it for our task.  \n",
        "The first time we load the model, it will be downloaded locally, and then cached for the future.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-10T16:41:50.286515Z",
          "start_time": "2021-02-10T16:41:50.192498Z"
        },
        "id": "M-VgT1c7pKmC"
      },
      "source": [
        "# We load a pretrain model with its weights. Alternatively, one might want to only load the model architecture.\n",
        "model = models.vgg16(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBa9PG8YULME"
      },
      "source": [
        "We can print the model to learn about its structure.\n",
        "Pay attention that you don't have to know the various types layers of the model such as convolution and ReLU (for now:) )."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB88_f-SUHxK"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qCjkxylUOze"
      },
      "source": [
        "Keras has a useful model summary, that we can also use for PyTorch models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKrDjETPUUz1"
      },
      "source": [
        "!pip install torchsummary \n",
        "from torchsummary import summary\n",
        "summary(model.to(device), (3, 256, 256))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jmlp9iHGU5Bx"
      },
      "source": [
        "We can see above that the final layer is a fully connected layer, from 4096 neurons to 1000 neurons, with a total of `4096 * 1000 + 1000 = 4,097,000` parameters. We add 1000 weights for the bias term of each output neuron.  \n",
        "\n",
        "So in total, VGG-16 has 138M parameters, and we've set them all to be trainable.\n",
        "\n",
        "However, VGG-16 and other networks created for ImageNet all have 1,000 neurons in their output, since they classify images to one of the 1,000 categories in the ImageNet challenge.  \n",
        "To use the network for our task, we need to replace the final fully-connected layer with one mapping to 9 neurons instead of 1000:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob7VB94PwlMn"
      },
      "source": [
        "# This code should output the number of input neurons to the final layer. We'll use it to create a new layer instead of it.\n",
        "last_layer = list(model.children())[-1]\n",
        "if hasattr(last_layer, 'in_features'):\n",
        "  num_ftrs = last_layer.in_features\n",
        "else:\n",
        "  num_ftrs = last_layer[-1].in_features\n",
        "\n",
        "num_ftrs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YffwvCiXwiC"
      },
      "source": [
        "To access and set a layer in the network, we reference it by name. In the example above, the final layer is `model.classifier[6]`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTKUigysWOmJ"
      },
      "source": [
        "# Here the size of each output sample is set to 2.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model.classifier[6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xCEMDVJX-9m"
      },
      "source": [
        "Let's now replace it with a linear layer with 4096 input features and 9 output features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bM4bnrQMX9h5"
      },
      "source": [
        "model.classifier[6] = nn.Linear(in_features=4096, out_features=9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlXzSmFCYQhh"
      },
      "source": [
        "Let's review our change in the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGfUb5bwYQth"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbJaJ3QgYTH5"
      },
      "source": [
        "summary(model.to(device), (3, 256, 256))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpTmZmOPYZ5U"
      },
      "source": [
        "Next, we define the loss, optimizer and LR scheduler."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-10T16:42:46.577559Z",
          "start_time": "2021-02-10T16:42:46.563241Z"
        },
        "id": "-6YpgLH2bGOE"
      },
      "source": [
        "# If a GPU is available, make the model use it\n",
        "model = model.to(device)\n",
        "\n",
        "# For a multi-class problem, you'd usually prefer CrossEntropyLoss()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use Stochastic Gradient Descent as the optimizer, with a learning rate of 0.001 and momentum\n",
        "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "\n",
        "num_epochs = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pm7kS8R0bGOC"
      },
      "source": [
        "Training the model\n",
        "------------------\n",
        "\n",
        "Now, let's write a general function to train a model. Here, we will\n",
        "illustrate:\n",
        "\n",
        "-  Scheduling the learning rate\n",
        "-  Saving the best model\n",
        "\n",
        "In the following, parameter ``scheduler`` is an LR scheduler object from\n",
        "``torch.optim.lr_scheduler``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-10T16:00:27.294647Z",
          "start_time": "2021-02-10T16:00:27.282629Z"
        },
        "id": "YeNm4HwpbGOD"
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    # Init variables that will save info about the best model\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                # Set model to training mode. \n",
        "                model.train()  \n",
        "            else:\n",
        "                # Set model to evaluate mode. In evaluate mode, we don't perform backprop and don't need to keep the gradients\n",
        "                model.eval()   \n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                # Prepare the inputs for GPU/CPU\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # ===== forward pass ======\n",
        "                with torch.set_grad_enabled(phase=='train'):\n",
        "                    # If we're in train mode, we'll track the gradients to allow back-propagation\n",
        "                    outputs = model(inputs) # apply the model to the inputs. The output is the softmax probability of each class\n",
        "                    _, preds = torch.max(outputs, 1) # \n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # ==== backward pass + optimizer step ====\n",
        "                    # This runs only in the training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward() # Perform a step in the opposite direction of the gradient\n",
        "                        optimizer.step() # Adapt the optimizer\n",
        "\n",
        "                # Collect statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                \n",
        "            if phase == 'train':\n",
        "                # Adjust the learning rate based on the scheduler\n",
        "                scheduler.step()  \n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            # Keep the results of the best model so far\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                # deepcopy the model\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {(time_elapsed // 60):.0f}m {(time_elapsed % 60):.0f}s')\n",
        "    print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJg-0nsubGOE"
      },
      "source": [
        "## Running the network\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r33C2_GhbGOF"
      },
      "source": [
        "### Train and evaluate\n",
        "It should take around 15-25 min on CPU. On GPU though, it takes substenitally less running time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-10T16:51:38.464026Z",
          "start_time": "2021-02-10T16:42:48.923785Z"
        },
        "id": "logUJ2VabGOF"
      },
      "source": [
        "model = train_model(model, \n",
        "                    dataloaders,\n",
        "                       criterion, \n",
        "                       optimizer_ft, \n",
        "                       exp_lr_scheduler,\n",
        "                       num_epochs=num_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wE_NVUyubGOD"
      },
      "source": [
        "### Visualizing the model predictions\n",
        "\n",
        "Let's define a generic function to display our model's predictions for a few images:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-10T16:02:27.625015Z",
          "start_time": "2021-02-10T16:02:27.605016Z"
        },
        "id": "dF9iahwEbGOE"
      },
      "source": [
        "def visualize_model(model, num_images=6):    \n",
        "    # Record the train/evaluate mode of the model, to restore it after we're done\n",
        "    was_training = model.training\n",
        "    # Set the model mode to evaluate\n",
        "    model.eval()\n",
        "    \n",
        "    images_so_far = 0\n",
        "    plt.figure(figsize=(2,1), dpi=300)\n",
        "\n",
        "    with torch.no_grad(): # No need to collect gradients when generating predictions\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "                \n",
        "        # Restore the model's train/evaluate mode\n",
        "        model.train(mode=was_training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-10T16:30:47.928248Z",
          "start_time": "2021-02-10T16:30:43.407030Z"
        },
        "id": "7KINOctNbGOF"
      },
      "source": [
        "visualize_model(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wzN5MiMZD0R"
      },
      "source": [
        "# Additional Tasks\n",
        "In the sections below, you'll experiment with PyTorch and NN yourself.  \n",
        "\n",
        "Before you start having fun on your own, let's review together how to get some predictions from our trained model.  \n",
        "\n",
        "As we've done in both our training and visualization code, we apply our model on some input with the command:  \n",
        "```python\n",
        "outputs = model(inputs)\n",
        "```\n",
        "\n",
        "So first let's load some input image using our data loaders. The relevant code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0Q_mw_OZ06c"
      },
      "source": [
        "inputs, labels = next(iter(dataloaders['train']))\n",
        "inputs = inputs.to(device)\n",
        "#print(inputs)\n",
        "\n",
        "labels = labels.to(device)\n",
        "#print(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGJ7tStSaRFO"
      },
      "source": [
        "Note that we got tensors. We can convert them into numpy objects. Since we've previously set them to use GPU, We'll need to set them to use CPU by calling to X.cpu().numpy() where X is the tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMf3TSBEaPkQ"
      },
      "source": [
        "labels.cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can apply the model on input tensors."
      ],
      "metadata": {
        "id": "PIR_xijirWzb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNs5EGMcamNL"
      },
      "source": [
        "outputs = model(inputs)\n",
        "\n",
        "print(outputs.shape)\n",
        "print(outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKAGAvaMauW5"
      },
      "source": [
        "Note that `outputs` have 16 \"rows\", one for each of the images in our batch, and each \"row\" has 9 values, for each of our classes.  \n",
        "The values are the activations of the neurons, before applying the softmax function to them. To apply the softmax function to them, we can run:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OomFFBnCbLji"
      },
      "source": [
        "torch.nn.functional.softmax(outputs, dim=1).cpu().detach().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26kRSsIc1GiD"
      },
      "source": [
        "## Task 1: Plot model convergence\n",
        "Adapt the code above to plot the loss and the accuracy every epoch. Show both the training and the validation performance.  \n",
        "Does our model overfit?  \n",
        "Do you have suggestions following these graphs? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rpk_gwT1G4H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xV_lgG2AySmW"
      },
      "source": [
        "## Task 2: Evaluate the model performance\n",
        "Write code that shows the performance of our model.  \n",
        "Show the classification report and the confusion matrix.  \n",
        "\n",
        "What can you say about the model so far?  \n",
        "Can you suggest a few ideas to improve it?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egbt6Ry6ySCI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIGMJhTGpKmG"
      },
      "source": [
        "## Task 3: Perform Error Analysis \n",
        "Error Analysis is an extremely important practice in Machine Learning research. It is rare that our base model works great out of the box. Proper error analysis helps us detect and fix issues in our DL code, data preprocessing and even in the data itself."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "k83euEIttpA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5ZtaZhspKmG"
      },
      "source": [
        "#### Review examples of top errors\n",
        "One of the basic techniques of Error Analysis is manually reviewing the top errors of the model - samples where the model was most confident about one class, but the true label was different.  \n",
        "Plot the top 10 errors of the model for each true class.  \n",
        "Do you spot any issue or pattern?  \n",
        "Try to see if you can improve the performance of the model following your insights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N4qWj-PpKmG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF8da2hbpKmF"
      },
      "source": [
        "## Task 4: Data Augmentation\n",
        "Manually labeling can be expensive, both in terms of money and of time. Data augmentations serve to increase the amount of data available for the classifier without requiring labeling more images.  \n",
        "\n",
        "The torch vision package allows easy augmentation of images using the data transforms.  \n",
        "Use and adapt the code below to try different augmentations, and discuss the results and the model improvements you got from these augmentations.\n",
        "\n",
        "[This guide](https://www.analyticsvidhya.com/blog/2019/12/image-augmentation-deep-learning-pytorch/) might help you along the way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-01-05T08:27:24.663664Z",
          "start_time": "2021-01-05T08:27:24.648104Z"
        },
        "id": "SzZmGCNWpKmF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gUIi9kIpKmF"
      },
      "source": [
        "## Task 5: Model Architectures\n",
        "In the course we'll cover in depth various DL architectures suggested to perform image classification. Among other things, these networks differ in depth (the number of layers), the number of weights (the network power), the composing layers, and more.  \n",
        "In the figure below, you can see the performance of different network architectures on the ImageNet Image Classification task, and the number of flops (atomic computations) required for them. \n",
        "\n",
        "![CNN performance/flops graph](https://miro.medium.com/max/1838/1*n16lj3lSkz2miMc_5cvkrA.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43YUheLNpKmF"
      },
      "source": [
        "In our code above we've used the `VGG16` architecture.  \n",
        "See if you can increase model performance by using alternative architectures. Start by trying the `mobilenet` for its light-weights and then try different ones from [torchvision.models](https://pytorch.org/vision/0.8/models.html).  \n",
        "\n",
        "Pay attention to the input dimensions that each network architecture expects as well as the last layer name (in our example it was `model.classifier[6]`) they use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VViX-6uAeuOn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c90UskRfpKmG"
      },
      "source": [
        "##  BONUS: Design your own Neural Network Architecture\n",
        "Take a stab at building your own NN architecture.  \n",
        "To allow you to experiment quickly, we'll limit it to 8 layers max, and up to 10 million parameters. Use [this PyTorch guide](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html) for reference.  \n",
        "Train it only on our provided images - we'll present the winner with the best results on the validation set!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tHGujsdpKmG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}