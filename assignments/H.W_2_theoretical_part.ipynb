{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4WWyW4tM2Ir"
      },
      "source": [
        "# Deep Learning Theoretical Aspects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1ZXXN9lM2Is"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy as sp\n",
        "import sklearn\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2qwj-IZM2Iw"
      },
      "source": [
        "Much of the power of neural networks comes from the nonlinearity that is inherited in activation functions.  \n",
        "Show that a network of N layers that uses a linear activation function can be reduced into a network with just an input and output layers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmDcfgIOM2Ix"
      },
      "outputs": [],
      "source": [
        "# Write your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e-VlB4eM2Iz"
      },
      "source": [
        "### Derivatives of Activation Functions\n",
        "Compute the derivative of these activation functions:\n",
        "\n",
        "1 Sigmoid\n",
        "<img src=\"https://cdn-images-1.medium.com/max/1200/1*Vo7UFksa_8Ne5HcfEzHNWQ.png\" width=\"150\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bk-7BzFQM2I0"
      },
      "outputs": [],
      "source": [
        "# Write your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0AiF6YjM2I3"
      },
      "source": [
        "2 Relu \n",
        "\n",
        "<img src=\"https://cloud.githubusercontent.com/assets/14886380/22743194/73ca0834-ee54-11e6-903f-a7efd247406b.png\" width=\"200\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWTRtEX8M2I4"
      },
      "outputs": [],
      "source": [
        "# Write your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tcbCKStM2I7"
      },
      "source": [
        "3 Softmax\n",
        "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/e348290cf48ddbb6e9a6ef4e39363568b67c09d3\" width=\"250\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Qb8zeNBM2I8"
      },
      "outputs": [],
      "source": [
        "# Write your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRE-pv-zM2I-"
      },
      "source": [
        "### Back Propagation\n",
        "Use the chain rule and backprop (also called the generalized delta rule) to compute the partial derivatives for these computations:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sJZ_0mWM2JA"
      },
      "source": [
        "```\n",
        "z = x1 + 5*x2 - 3*x3^2\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPXdNKsGM2JA"
      },
      "outputs": [],
      "source": [
        "# Write your answer here, using Markdown, image or any other suitable format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgwnBRJgM2JD"
      },
      "source": [
        "```\n",
        "z = x1*(x2-4) + exp(x3^2) / 5*x4^2\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQ1igYpxM2JE"
      },
      "outputs": [],
      "source": [
        "# Write your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCIx61WAM2JI"
      },
      "source": [
        "```\n",
        "z = 1/x3 + exp( (x1+5*(x2+3)) ^2 )\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSdvzQTlM2JJ"
      },
      "outputs": [],
      "source": [
        "# Write your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIsnCby5M2Jt"
      },
      "source": [
        "#### Gradient Checking\n",
        "When computing the gradient yourself, it's recommended to manually check the gradient to make sure you haven't made an error.  \n",
        "We'll use the following equation for this, which produces more robust results than the standard definition of a derivative:\n",
        "\n",
        "\n",
        "<img src=\"http://ufldl.stanford.edu/wiki/images/math/a/2/3/a23bea0ab48ded7b9a979b68f6356613.png\" width=\"250\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVqcckZwM2Jt"
      },
      "source": [
        "We'll numerically approximate it using:\n",
        "\n",
        "<img src=\"http://ufldl.stanford.edu/wiki/images/math/4/8/a/48a000aed96c8595fcca2a45f48343ce.png\" width=\"250\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xAfbLz6M2Ju"
      },
      "source": [
        "Write a function that evaluates the gradient locally and use it to numerically compute the gradient along several randomly chosen dimensions (i.e. compute the partial derivative).\n",
        "Compare your results with your analytically computed gradient. The numbers should match almost exactly (if you use a small-enough epsilon. There might be very small differences due to calculation rounding)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9q5tPe8JM2Ju"
      },
      "outputs": [],
      "source": [
        "# Write your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvTBLm44M2Jq"
      },
      "source": [
        "### Puppy or bagel?\n",
        "We've seen in class the (hopefully) funny examples of challenging images (Chihuahua or muffin, puppy or bagel etc.). \n",
        "\n",
        "Let's say you were asked by someone to find more examples like that. You are able to call the 3 neural networks that won the recent ImageNet challenges, and get their predictions (the entire vector of probabilities for the 1000 classes).  \n",
        "\n",
        "Describe methods that might assist you in finding more examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsTYNPDvM2Jr"
      },
      "outputs": [],
      "source": [
        "# Write your answer here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "assignment1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}